{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 568 entries, 0 to 567\n",
      "Data columns (total 11 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   pregnant   568 non-null    int64  \n",
      " 1   plasma     568 non-null    int64  \n",
      " 2   diastolic  568 non-null    int64  \n",
      " 3   triceps    568 non-null    int64  \n",
      " 4   serum      568 non-null    int64  \n",
      " 5   bodymass   568 non-null    float64\n",
      " 6   pedigree   568 non-null    float64\n",
      " 7   age        568 non-null    int64  \n",
      " 8   alea1      568 non-null    float64\n",
      " 9   alea2      568 non-null    float64\n",
      " 10  diabete    568 non-null    int64  \n",
      "dtypes: float64(4), int64(7)\n",
      "memory usage: 48.9 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#chargement des données d'apprentissage\n",
    "import pandas\n",
    "DTrain = pandas.read_excel(\"diabete_reg_logistique.xlsx\", sheet_name = \"apprentissage\")\n",
    "#info\n",
    "print(DTrain.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nous isolons la variable cible (Y) et les explicatives potentielles (X) dans deux structures distinctes.\n",
    "Nous comptabilisons les effectifs par classe. Nous avons 372 personnes non atteintes et 196 diabètes\n",
    "dans notre échantillon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    372\n",
      "1    196\n",
      "Name: diabete, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#y (diabete) est la dernière colonne\n",
    "yTrain = DTrain.iloc[:,-1]\n",
    "#X (les autres) sont les variables qui précèdent la dernière\n",
    "XTrain = DTrain.iloc[:,:-1]\n",
    "#comptage des modalités de y\n",
    "print(yTrain.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nous réalisons les mêmes étapes sur notre échantillon « test ». Nous chargeons les données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 200 entries, 0 to 199\n",
      "Data columns (total 11 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   pregnant   200 non-null    int64  \n",
      " 1   plasma     200 non-null    int64  \n",
      " 2   diastolic  200 non-null    int64  \n",
      " 3   triceps    200 non-null    int64  \n",
      " 4   serum      200 non-null    int64  \n",
      " 5   bodymass   200 non-null    float64\n",
      " 6   pedigree   200 non-null    float64\n",
      " 7   age        200 non-null    int64  \n",
      " 8   alea1      200 non-null    float64\n",
      " 9   alea2      200 non-null    float64\n",
      " 10  diabete    200 non-null    int64  \n",
      "dtypes: float64(4), int64(7)\n",
      "memory usage: 17.3 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#chargement des données test\n",
    "DTest = pandas.read_excel(\"diabete_reg_logistique.xlsx\", sheet_name = \"test\")\n",
    "#info\n",
    "print(DTest.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  puis nous préparons les structures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    128\n",
      "1     72\n",
      "Name: diabete, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#y (diabete) est la dernière colonne\n",
    "yTest = DTest.iloc[:,-1]\n",
    "#X (les autres) sont les variables qui précèdent la dernière\n",
    "XTest = DTest.iloc[:,:-1]\n",
    "#comptage des modalités de y\n",
    "print(yTest.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Régression logistique avec “statsmodels”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12.0\n"
     ]
    }
   ],
   "source": [
    "#importation de la librairie de calcul\n",
    "import statsmodels as sm\n",
    "#vérification de version\n",
    "print(sm.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modélisation et inspection des résultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 568 entries, 0 to 567\n",
      "Data columns (total 11 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   const      568 non-null    float64\n",
      " 1   pregnant   568 non-null    int64  \n",
      " 2   plasma     568 non-null    int64  \n",
      " 3   diastolic  568 non-null    int64  \n",
      " 4   triceps    568 non-null    int64  \n",
      " 5   serum      568 non-null    int64  \n",
      " 6   bodymass   568 non-null    float64\n",
      " 7   pedigree   568 non-null    float64\n",
      " 8   age        568 non-null    int64  \n",
      " 9   alea1      568 non-null    float64\n",
      " 10  alea2      568 non-null    float64\n",
      "dtypes: float64(5), int64(6)\n",
      "memory usage: 48.9 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#importation de l'outil\n",
    "from statsmodels.tools import add_constant\n",
    "#données X avec la constante\n",
    "XTrainBis = sm.tools.add_constant(XTrain)\n",
    "#vérifier la structure\n",
    "print(XTrainBis.info())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# ...\n",
    "Une colonne « const » de valeur 1 est insérée dans la première colonne. Nous visualisons les\n",
    "premières lignes de la structure pour bien comprendre la nouvelle configuration de la matrice\n",
    "des explicatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   const  pregnant  plasma  diastolic  triceps  serum  bodymass  pedigree  \\\n",
      "0    1.0         0     138          0        0      0      36.3     0.933   \n",
      "1    1.0         4     142         86        0      0      44.0     0.645   \n",
      "2    1.0         3     142         80       15      0      32.4     0.200   \n",
      "3    1.0         3     113         50       10     85      29.5     0.626   \n",
      "4    1.0         5      88         78       30      0      27.6     0.258   \n",
      "\n",
      "   age  alea1  alea2  \n",
      "0   25  0.338  0.188  \n",
      "1   22  0.835  0.711  \n",
      "2   63  0.493  0.845  \n",
      "3   25  0.857  0.821  \n",
      "4   37  0.045  0.392  \n"
     ]
    }
   ],
   "source": [
    "#visualisation des premières lignes de la structure\n",
    "#premières lignes\n",
    "print(XTrainBis.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modélisation Logit"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Nous pouvons lancer la régression maintenant. Après appel du constructeur de la classe Logit() où\n",
    "nous passons les données, nous faisons appel à la fonction fit() qui génère un objet résultat doté de\n",
    "propriétés et méthodes qui nous seront très utiles par la suite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.476159\n",
      "         Iterations 6\n"
     ]
    }
   ],
   "source": [
    "#importation de la classe de calcul\n",
    "from statsmodels.api import Logit\n",
    "#régression logistique - on passe la cible et les explicatives\n",
    "lr = Logit(endog=yTrain.astype(float),exog=XTrainBis.astype(float))\n",
    "#lancer les calculs\n",
    "#algorithme de Newton-Raphson utilisé par défaut\n",
    "#https://www.statsmodels.org/stable/generated/statsmodels.discrete.discrete_model.Logit.fit.html\n",
    "res = lr.fit()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Par défaut, l’outil s’appuie sur l’algorithme de Newton-Raphson (LIVRE, section 1.5). D’autres\n",
    "procédures d’optimisation sont disponibles. 6 itérations ont été nécessaires pour maximiser \n",
    "la logvraisemblance (LIVRE, section 1.4, équation 1.8)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nous affichons ensuite les propriétés de l’objet produit par fit()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_cache', '_data_attr', '_data_in_cache', '_get_endog_name', '_get_robustcov_results', '_use_t', 'aic', 'bic', 'bse', 'conf_int', 'cov_kwds', 'cov_params', 'cov_type', 'df_model', 'df_resid', 'f_test', 'fittedvalues', 'get_margeff', 'initialize', 'k_constant', 'llf', 'llnull', 'llr', 'llr_pvalue', 'load', 'mle_retvals', 'mle_settings', 'model', 'nobs', 'normalized_cov_params', 'params', 'pred_table', 'predict', 'prsquared', 'pvalues', 'remove_data', 'resid_dev', 'resid_generalized', 'resid_pearson', 'resid_response', 'save', 'scale', 'set_null_options', 'summary', 'summary2', 't_test', 't_test_pairwise', 'tvalues', 'use_t', 'wald_test', 'wald_test_terms']\n"
     ]
    }
   ],
   "source": [
    "#propriétés de l'objet résultat\n",
    "#https://www.statsmodels.org/stable/generated/statsmodels.discrete.discrete_model.LogitResults.html\n",
    "print(dir(res))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Les résultats détaillés de la régression sont affichés avec la commande summary()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                diabete   No. Observations:                  568\n",
      "Model:                          Logit   Df Residuals:                      557\n",
      "Method:                           MLE   Df Model:                           10\n",
      "Date:                Sun, 23 May 2021   Pseudo R-squ.:                  0.2610\n",
      "Time:                        20:14:52   Log-Likelihood:                -270.46\n",
      "converged:                       True   LL-Null:                       -365.99\n",
      "Covariance Type:            nonrobust   LLR p-value:                 1.179e-35\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -8.1902      0.887     -9.234      0.000      -9.929      -6.452\n",
      "pregnant       0.0947      0.038      2.467      0.014       0.019       0.170\n",
      "plasma         0.0322      0.004      7.826      0.000       0.024       0.040\n",
      "diastolic     -0.0165      0.006     -2.605      0.009      -0.029      -0.004\n",
      "triceps        0.0030      0.008      0.378      0.706      -0.012       0.018\n",
      "serum         -0.0009      0.001     -0.942      0.346      -0.003       0.001\n",
      "bodymass       0.0947      0.018      5.350      0.000       0.060       0.129\n",
      "pedigree       0.7917      0.356      2.223      0.026       0.094       1.490\n",
      "age            0.0228      0.011      2.020      0.043       0.001       0.045\n",
      "alea1         -0.2241      0.373     -0.601      0.548      -0.955       0.506\n",
      "alea2          0.3816      0.378      1.009      0.313      -0.360       1.123\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "#résumé des résultats\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les résultats sont tout à fait conformes à ce que l’on pourrait attendre de ce type d’outil. Dans la\n",
    "partie haute, nous y reviendrons, nous disposons des informations globales sur la modélisation. Dans\n",
    "la partie basse, nous visualisons les coefficients estimés et les éléments pour l’inférence statistique\n",
    "(écarts-type estimés des coefficients, statistique de test de significativité, p-value du test de\n",
    "significativité, intervalle de confiance des coefficients à 95%)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Important\n",
    "Des calculs intermédiaires sont possibles relativement simplement. Par exemple, si nous souhaitons\n",
    "obtenir les intervalles de confiance à 90% des coefficients, nous faisons appel à la méthode\n",
    "conf_int() de l’objet résultat fourni par fit().\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  0         1\n",
      "const     -9.649033 -6.731344\n",
      "pregnant   0.031583  0.157913\n",
      "plasma     0.025417  0.038946\n",
      "diastolic -0.026846 -0.006063\n",
      "triceps   -0.010009  0.015978\n",
      "serum     -0.002555  0.000695\n",
      "bodymass   0.065580  0.123814\n",
      "pedigree   0.205952  1.377405\n",
      "age        0.004235  0.041325\n",
      "alea1     -0.837232  0.388943\n",
      "alea2     -0.240471  1.003609\n"
     ]
    }
   ],
   "source": [
    "#intervalle de confiance des coefficients à 90%\n",
    "print(res.conf_int(alpha=0.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation globale du modèle en resubstitution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L’évaluation en resubstitution consiste à utiliser les données d’apprentissage même pour mesurer la\n",
    "qualité du modèle : en termes de performances prédictives, nous savons dans ce cas que les\n",
    "indicateurs calculés sont souvent trop optimistes ; en termes d’approximation des probabilités\n",
    "d’appartenance aux classes, ce qui donne lieu à des tests statistiques usuels dans la pratique de la\n",
    "régression logistique mais peu connus en machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matrice de confusion en resubstitution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La matrice de confusion résulte de la confrontation entre les classes observées (valeurs de la valeur\n",
    "cible) et estimées à l’aide du modèle (LIVRE, section 2.1). La propriété (.fittedvalues) correspond aux\n",
    "valeurs du LOGIT (LIVRE, section 1.3) calculées sur les données d’apprentissage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      0.992453\n",
      "1      0.606054\n",
      "2      0.265769\n",
      "3     -1.161582\n",
      "4     -2.278191\n",
      "         ...   \n",
      "563   -0.288489\n",
      "564   -1.807065\n",
      "565   -1.622167\n",
      "566    0.239538\n",
      "567   -2.377756\n",
      "Length: 568, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#valeurs estimées par la régression en resubstitution\n",
    "print(res.fittedvalues)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons reproduire ces valeurs à partir des coefficients de la régression et de la description\n",
    "des observations. Pour le premier individu (n°0) par exemple :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "const       -8.190188\n",
      "pregnant     0.094748\n",
      "plasma       0.032181\n",
      "diastolic   -0.016455\n",
      "triceps      0.002984\n",
      "serum       -0.000930\n",
      "bodymass     0.094697\n",
      "pedigree     0.791679\n",
      "age          0.022780\n",
      "alea1       -0.224145\n",
      "alea2        0.381569\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Voici les coefficients estimés\n",
    "print(res.params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description du 1er individu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "const          1.000\n",
      "pregnant       0.000\n",
      "plasma       138.000\n",
      "diastolic      0.000\n",
      "triceps        0.000\n",
      "serum          0.000\n",
      "bodymass      36.300\n",
      "pedigree       0.933\n",
      "age           25.000\n",
      "alea1          0.338\n",
      "alea2          0.188\n",
      "Name: 0, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#voici la description du premier individu\n",
    "print(XTrainBis.iloc[0,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Le produit scalaire – valeur du LOGIT pour l’individu n°0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9924529545060738\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "print(numpy.sum(res.params*XTrainBis.iloc[0,:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons déduire du LOGIT la prédiction en utilisant une règle d’affectation simple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 1 0 0 1 0 1 0 0 1 0 0\n",
      " 1 0 1 1 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 1 1 0 0 1 0 1 1 1 0 0 0 0 1 1 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 1 1 0 0 0 0 0 0 0 1 1 1 0 1 0 0 1\n",
      " 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 1 0 0 1 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 1 1 0 0 1 1 0 0\n",
      " 0 0 0 1 1 0 1 0 1 0 0 1 0 1 1 0 1 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1\n",
      " 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 1 0 1 0 1 1 0 1 0 0 0 0\n",
      " 0 0 1 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 1 1 1 0 1 0 1 1 1 1 0 0 0 1 0 1 0 0\n",
      " 0 0 1 1 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 1 1 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 1 1 1 1 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 1 1 0 0 0 1 0 1 0 0 1 0 0 0 0 1 1 0\n",
      " 0 0 0 0 0 0 0 1 0 0 1 1 0 1 0 0 0 0 0 1 0 1 0 0 0 1 0 0 1 1 0 0 1 0 0 0 0\n",
      " 0 1 1 0 0 0 1 0 0 0 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "#la règle d'affectation consiste à confronter le LOGIT à la valeur seuil 0\n",
    "predResub = numpy.where(res.fittedvalues > 0, 1, 0)\n",
    "print(predResub)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Via un tableau croisé entre les classes observées et prédites, nous obtenons la matrice de confusion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col_0      0    1\n",
      "diabete          \n",
      "0        329   43\n",
      "1         84  112\n"
     ]
    }
   ],
   "source": [
    "#on peut en déduire la matrice de confusion\n",
    "print(pandas.crosstab(yTrain,predResub))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Laquelle peut être obtenue directement via la fonction .pred_table() de l’objet régression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[329.  43.]\n",
      " [ 84. 112.]]\n"
     ]
    }
   ],
   "source": [
    "#matrice de confusion en resubstitution directement fournie par l'outil\n",
    "print(res.pred_table())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plusieurs indicateurs peuvent être extraits de cette matrice (LIVRE, section 2.1.1). Nous y\n",
    "reviendrons plus loin lorsqu’elle sera construite à partir de l’échantillon test. Les valeurs obtenues\n",
    "seront autrement plus représentatives des performances réelles du modèle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pseudo-R2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les pseudo-R² sont des indicateurs similaires dans l’esprit au R² de la régression linéaire. Il sont\n",
    "basés sur la confrontation entre la log-vraisemblance du modèle et de celle du modèle trivial\n",
    "composé uniquement de la constante (null model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# R² de McFadden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log-vraisemblance du modèle : -270.4585\n",
      "Log-vraisemblance du null modèle : -365.9860\n"
     ]
    }
   ],
   "source": [
    "#accès à la log-vraisemblance du modèle\n",
    "print(\"Log-vraisemblance du modèle : %.4f\" % (res.llf))\n",
    "#log-vraisemblance du null modèle\n",
    "print(\"Log-vraisemblance du null modèle : %.4f\" % (res.llnull))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26101398077836613\n"
     ]
    }
   ],
   "source": [
    "#R2 de McFadden\n",
    "R2MF = 1 - res.llf / res.llnull\n",
    "print(R2MF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26101398077836613\n"
     ]
    }
   ],
   "source": [
    "#qui est founi directement par l'outil\n",
    "print(res.prsquared)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# R² de Cox et Snell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 de Cox - Snell : 0.2856\n"
     ]
    }
   ],
   "source": [
    "#exponenielle de LL_null\n",
    "L0 = numpy.exp(res.llnull)\n",
    "#exponentielle de LL_modèle\n",
    "La = numpy.exp(res.llf)\n",
    "#taille de l'échantillon\n",
    "n = DTrain.shape[0]\n",
    "#R2 de Cox et Snell\n",
    "R2CS = 1.0 - (L0 / La)**(2.0/n)\n",
    "print(\"R2 de Cox - Snell : %.4f\" % (R2CS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# R² de Nagelkerke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 de Nagelkerke : 0.3943\n"
     ]
    }
   ],
   "source": [
    "#max du R2 de COx-Snell\n",
    "maxR2CS = 1.0 - (L0)**(2.0/n)\n",
    "#R2 de Nagelkerke\n",
    "R2N = R2CS / maxR2CS\n",
    "print(\"R2 de Nagelkerke : %.4f\" % (R2N))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation basée sur les scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L’évaluation basée sur les scores analyse dans quelle mesure les probabilités d’affectation à la\n",
    "modalité cible (Y = 1) fournis par le modèle, que l’on nommera « scores » dans ce qui suit, sont de\n",
    "qualité satisfaisante. Nous pouvons les calculer en appliquant la fonction logistique (.cdf) sur le\n",
    "LOGIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.72957215 0.64704005 0.56605385 0.23837986 0.09294535 0.21707393\n",
      " 0.13273869 0.07248227 0.21364505 0.04597785]\n"
     ]
    }
   ],
   "source": [
    "#scores fournis par la régression\n",
    "scores = lr.cdf(res.fittedvalues)\n",
    "print(scores[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# vérifions la première valeur (individu n°0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score du 1er individu 0.7296\n"
     ]
    }
   ],
   "source": [
    "s0 = 1.0/(1.0 + numpy.exp(-1.0 * res.fittedvalues[0]))\n",
    "print(\"Score du 1er individu %.4f\" % (s0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diagramme de fiabilité"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le diagramme de fiabilité est un outil de diagnostic graphique. Il oppose les scores estimés par le\n",
    "modèle aux « scores observés ». Ces derniers sont obtenus en calculant la proportion des positifs\n",
    "observés dans des groupes d’observations. Lesquels groupes sont constitués à partir d’un\n",
    "découpage en intervalles de largeurs égales des probabilités d’affectation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     y     score                            intv\n",
      "0    1  0.729572                  (0.587, 0.781]\n",
      "1    1  0.647040                  (0.587, 0.781]\n",
      "2    0  0.566054                  (0.392, 0.587]\n",
      "3    0  0.238380                  (0.198, 0.392]\n",
      "4    0  0.092945  (0.0013900000000000002, 0.198]\n",
      "..  ..       ...                             ...\n",
      "563  0  0.428374                  (0.392, 0.587]\n",
      "564  0  0.140993  (0.0013900000000000002, 0.198]\n",
      "565  0  0.164906  (0.0013900000000000002, 0.198]\n",
      "566  0  0.559600                  (0.392, 0.587]\n",
      "567  0  0.084885  (0.0013900000000000002, 0.198]\n",
      "\n",
      "[568 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "#data frame temporaire avec y et les scores\n",
    "df = pandas.DataFrame({\"y\":yTrain,\"score\":scores})\n",
    "#5 intervalles de largeur égales\n",
    "intv = pandas.cut(df.score,bins=5,include_lowest=True)\n",
    "#intégrées dans le df\n",
    "df['intv'] = intv\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir de ce dataset, nous pouvons calculer la moyenne des scores estimés dans chaque groupe\n",
    "délimité par les intervalles.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                   score\n",
      "intv                                    \n",
      "(0.0013900000000000002, 0.198]  0.102093\n",
      "(0.198, 0.392]                  0.285405\n",
      "(0.392, 0.587]                  0.476966\n",
      "(0.587, 0.781]                  0.679209\n",
      "(0.781, 0.976]                  0.857792\n"
     ]
    }
   ],
   "source": [
    "#moyenne des scores par groupe\n",
    "m_score = df.pivot_table(index=\"intv\",values=\"score\",aggfunc=\"mean\")\n",
    "print(m_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puis la proportion des observations (scores observés) positives dans les mêmes groupes. \n",
    "La variable cible Y étant binaire (0/1), la moyenne fait très bien l’affaire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                       y\n",
      "intv                                    \n",
      "(0.0013900000000000002, 0.198]  0.092511\n",
      "(0.198, 0.392]                  0.291971\n",
      "(0.392, 0.587]                  0.539474\n",
      "(0.587, 0.781]                  0.637681\n",
      "(0.781, 0.976]                  0.847458\n"
     ]
    }
   ],
   "source": [
    "#moyenne des y - qui équivaut à une proportion puisque 0/1\n",
    "m_y = df.pivot_table(index=\"intv\",values=\"y\",aggfunc=\"mean\")\n",
    "print(m_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le diagramme de fiabilité (reliability diagram) est un graphique nuage de points opposant les scores\n",
    "estimés et observés. S’ils forment une droite, nous pouvons considérer que la modélisation est\n",
    "pertinente car le modèle arrive à approcher de manière satisfaisante l’appartenance aux classes des\n",
    "individus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#pouvoir faire apparaître le graphique dans le notebook\n",
    "%matplotlib inline\n",
    "#insérer le graphique\n",
    "import matplotlib.pyplot as plt\n",
    "#construire la diagonale\n",
    "plt.plot(numpy.arange(0,1,0.1),numpy.arange(0,1,0.1),'b')\n",
    "#rajouter notre diagramme\n",
    "plt.plot(m_score,m_y,\"go-\")\n",
    "#titre\n",
    "plt.title(\"Diagramme de fiabilité\")\n",
    "#faire apparaître\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour ce qui est de notre exemple, la modélisation semble relativement intéressante même si nous\n",
    "notons ici ou là des écarts par rapport à la première bissectrice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test de Hosmer-Lemeshow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le test de Hosmer-Lemeshow procède de la même idée de confrontation entre scores estimés et\n",
    "observés. Mais il quantifie les écarts à l’aide d’un indicateur statistique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     y     score              intv\n",
      "0    1  0.729572    (0.624, 0.787]\n",
      "1    1  0.647040    (0.624, 0.787]\n",
      "2    0  0.566054    (0.458, 0.624]\n",
      "3    0  0.238380    (0.198, 0.264]\n",
      "4    0  0.092945  (0.0602, 0.0968]\n",
      "..  ..       ...               ...\n",
      "563  0  0.428374    (0.345, 0.458]\n",
      "564  0  0.140993   (0.0968, 0.142]\n",
      "565  0  0.164906    (0.142, 0.198]\n",
      "566  0  0.559600    (0.458, 0.624]\n",
      "567  0  0.084885  (0.0602, 0.0968]\n",
      "\n",
      "[568 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "#data frame temporaire avec y et les scores\n",
    "df = pandas.DataFrame({\"y\":yTrain,\"score\":scores})\n",
    "#10 intervalles de fréquences égales\n",
    "intv = pandas.qcut(df.score,q=10)\n",
    "#intégrées dans le df\n",
    "df['intv'] = intv\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir de ce tableau, nous pouvons retracer les étapes du calcul de l’indicateur statistique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Effectifs par groupe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[57 57 57 56 57 57 56 57 57 57]\n"
     ]
    }
   ],
   "source": [
    "n_tot = df.pivot_table(index=\"intv\",values=\"y\",aggfunc=\"count\").values[:,0]\n",
    "print(n_tot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Somme des scores par groupes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.02272734  4.56665844  7.0056866   9.57994925 13.44277186 17.2915872\n",
      " 22.43331173 30.64510151 39.97361233 49.03859374]\n"
     ]
    }
   ],
   "source": [
    "s_scores = df.pivot_table(index='intv',values=\"score\",aggfunc=\"sum\").values[:,0]\n",
    "print(s_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nombre de positifs par groupe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3  2  2 14 13 16 28 33 37 48]\n"
     ]
    }
   ],
   "source": [
    "n_pos = df.pivot_table(index=\"intv\",values=\"y\",aggfunc=\"sum\").values[:,0]\n",
    "print(n_pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nombre de négatifs par groupe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[54 55 55 42 44 41 28 24 20  9]\n"
     ]
    }
   ],
   "source": [
    "n_neg = n_tot - n_pos\n",
    "print(n_neg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous nous sommes basés sur l’équation en 2 parties "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.44729672142736\n"
     ]
    }
   ],
   "source": [
    "C1 = numpy.sum((n_pos - s_scores)**2/s_scores)\n",
    "print(C1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9000074327988936\n"
     ]
    }
   ],
   "source": [
    "C2 = numpy.sum((n_neg - (n_tot - s_scores))**2/((n_tot - s_scores)))\n",
    "print(C2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistique de Hosmer-Lemeshow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.347304154226254\n"
     ]
    }
   ],
   "source": [
    "HL = C1 + C2\n",
    "print(HL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laquelle suite une loi du KHI-2 à 8 degrés de liberté"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13636768680069833\n"
     ]
    }
   ],
   "source": [
    "#librairie scipy\n",
    "import scipy\n",
    "#probabilité critique\n",
    "pvalue = 1.0 - scipy.stats.chi2.cdf(HL,8)\n",
    "print(pvalue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Au risque 5%, nous ne pouvons pas rejeter l’hypothèse de compatibilité de notre modèle avec les\n",
    "données."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests de significativité des coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cette partie reprend la trame du chapitre 3 du LIVRE. Il s’agit de tester la nullité de tout ou partie des\n",
    "coefficients de la régression. Nous nous appuyons sur les 2 approches qui font référence : le test du\n",
    "rapport de vraisemblance et le test de Wald."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test de significativité globale de la régression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il s’agit de vérifier si les coefficients, à l’exception de la constante, sont tous simultanément nuls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# a- Via le test du rapport de vraisemblance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce test est fondé sur la confrontation des déviances du modèle et du null modèle (modèle trivial\n",
    "composé exclusivement de la constante). On se rappelle que la déviance est égale à (-2) x logvraisemblance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deviance du modèle : 540.9170 \n",
      "Deviance du modèle : 731.9720 \n",
      "Stat. du rapport de vraisemblance : 191.0549 \n"
     ]
    }
   ],
   "source": [
    "#déviance du modèle\n",
    "dev_modele = (-2) * res.llf\n",
    "print(\"Deviance du modèle : %.4f \" % (dev_modele))\n",
    "#déviance du modèle trivial\n",
    "dev_null = (-2) * res.llnull\n",
    "print(\"Deviance du modèle : %.4f \" % (dev_null))\n",
    "#statistique du rapport de vraisemblance\n",
    "LR_stat = dev_null - dev_modele\n",
    "print(\"Stat. du rapport de vraisemblance : %.4f \" % (LR_stat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stat. du rapport de vraisemblance via l'objet résultat : 191.0549\n"
     ]
    }
   ],
   "source": [
    "#laquelle était fournie directement par l'objet\n",
    "print(\"Stat. du rapport de vraisemblance via l'objet résultat : %.4f\" % (res.llr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notre calcul rejoint la valeur renvoyée par la propriété dédiée de l’objet régression. C’est toujours\n",
    "rassurant. Le degré de liberté est égal au nombre de paramètres retirés du modèle. Sous l’hypothèse\n",
    "nulle (tous les coefficients sont simultanément égaux à zéro), la statistique suit une loi du KHI-2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.0\n"
     ]
    }
   ],
   "source": [
    "#degré de liberté du test (nb. de coef. estimés excepté la constante)\n",
    "print(res.df_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "#p-value du test\n",
    "pvalue = 1.0 - scipy.stats.chi2.cdf(res.llr,res.df_model)\n",
    "print(pvalue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1793104380832713e-35\n"
     ]
    }
   ],
   "source": [
    "#laquelle était également fournie par l'objet\n",
    "print(res.llr_pvalue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encore une fois, nos calculs concordent avec la valeur de la p-value restituée par l’objet. Au risque\n",
    "5%, nous pouvons rejeter l’hypothèse de nullité des coefficients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# b) Via les comparaisons des critères AIC et BIC"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Une autre approche méconnue pour évaluer la qualité globale du modèle consiste à confronter les\n",
    "critères AIC (Akaike ; LIVRE, section 7.2.1, équation 7.2) ou BIC (Schwartz ; LIVRE, section 7.2.1,\n",
    "équation 7.3) du modèle étudié avec ceux du modèle trivial (null modèle).\n",
    "Si (AIC_modèle < AIC_null), nous pouvons conclure que notre modèle est globalement pertinent\n",
    "(idem pour le critère BIC).\n",
    "Critère AIC. L’AIC du modèle est restituée par une des propriétés de l’objet. Nous devons en\n",
    "revanche calculer l’AIC_null à partir de la log-vraisemblance du modèle trivial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIC du modèle : 562.9170\n",
      "AIC du modèle trivial : 733.9720\n"
     ]
    }
   ],
   "source": [
    "#AIC du modèle\n",
    "print(\"AIC du modèle : %.4f\" % (res.aic))\n",
    "#AIC du modèle trivial - 1 seul param. estimé, la constante\n",
    "aic_null = (-2) * res.llnull + 2 * (1)\n",
    "print(\"AIC du modèle trivial : %.4f\" % (aic_null))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Apparemment, notre modèle est globalement pertinent.\n",
    "Critère BIC. Nous pouvons adopter la même démarche pour le critère BIC. Ce dernier a la\n",
    "particularité de pénaliser davantage la complexité (le nombre de paramètres à estimer). Il nous\n",
    "indique que le modèle n’est pas si pertinent que cela finalement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BIC du modèle : 610.6804\n",
      "BIC du modèle trivial : 738.3141\n"
     ]
    }
   ],
   "source": [
    "#BIC du modèle\n",
    "print(\"BIC du modèle : %.4f\" % (res.bic))\n",
    "#BIC du modèle trivial - 1 seul param. estimé, la constante\n",
    "bic_null = (-2) * res.llnull + numpy.log(n) * (1)\n",
    "print(\"BIC du modèle trivial : %.4f\" % (bic_null))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tester la significativité d’un coefficient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le test le plus immédiat est celui de Wald. Il suffit de regarder les p-value\n",
    "associées à chaque variable dans le résumé des résultats. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En confrontant les résultats de la régression avec et sans la variable incriminée. \n",
    "\n",
    "Par exemple, pour évaluer le coefficient associé à la variable “pregnant”. Nous effectuons la régression en l’excluant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 568 entries, 0 to 567\n",
      "Data columns (total 10 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   const      568 non-null    float64\n",
      " 1   plasma     568 non-null    int64  \n",
      " 2   diastolic  568 non-null    int64  \n",
      " 3   triceps    568 non-null    int64  \n",
      " 4   serum      568 non-null    int64  \n",
      " 5   bodymass   568 non-null    float64\n",
      " 6   pedigree   568 non-null    float64\n",
      " 7   age        568 non-null    int64  \n",
      " 8   alea1      568 non-null    float64\n",
      " 9   alea2      568 non-null    float64\n",
      "dtypes: float64(5), int64(5)\n",
      "memory usage: 44.5 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#data frame sans \"Sex\"\n",
    "XTrain_wo_pregnant = XTrainBis.drop(columns=['pregnant'])\n",
    "print(XTrain_wo_pregnant.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.481626\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                diabete   No. Observations:                  568\n",
      "Model:                          Logit   Df Residuals:                      558\n",
      "Method:                           MLE   Df Model:                            9\n",
      "Date:                Sun, 23 May 2021   Pseudo R-squ.:                  0.2525\n",
      "Time:                        20:14:55   Log-Likelihood:                -273.56\n",
      "converged:                       True   LL-Null:                       -365.99\n",
      "Covariance Type:            nonrobust   LLR p-value:                 4.927e-35\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -8.2988      0.884     -9.386      0.000     -10.032      -6.566\n",
      "plasma         0.0320      0.004      7.831      0.000       0.024       0.040\n",
      "diastolic     -0.0163      0.006     -2.566      0.010      -0.029      -0.004\n",
      "triceps        0.0041      0.008      0.519      0.604      -0.011       0.020\n",
      "serum         -0.0011      0.001     -1.085      0.278      -0.003       0.001\n",
      "bodymass       0.0940      0.018      5.362      0.000       0.060       0.128\n",
      "pedigree       0.7213      0.354      2.035      0.042       0.027       1.416\n",
      "age            0.0381      0.010      4.007      0.000       0.019       0.057\n",
      "alea1         -0.1865      0.371     -0.503      0.615      -0.913       0.540\n",
      "alea2          0.3951      0.377      1.048      0.295      -0.344       1.134\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "#régression sans Sex\n",
    "lr_wo_pregnant = Logit(yTrain,XTrain_wo_pregnant)\n",
    "#résultats\n",
    "res_wo_pregnant = lr_wo_pregnant.fit()\n",
    "#affichage\n",
    "print(res_wo_pregnant.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La statistique de test est obtenue par l’écart entre les déviances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.210139293948032\n"
     ]
    }
   ],
   "source": [
    "#statistique de test - différence entre les déviances\n",
    "LR_pregnant = (-2) * res_wo_pregnant.llf - (-2) * res.llf\n",
    "print(LR_pregnant)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sous H0, le coefficient associé à « pregnant » est nul, elle suit une loi du KHI-2 à 6 (vérifier 1 ou 6 !!!!) degrés de liberté"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Degré de liberté du test : 1\n",
      "Probabilité critique : 0.0127\n"
     ]
    }
   ],
   "source": [
    "#degré de liberté = 1 puisqu'un seul coef. retiré\n",
    "ddl = res_wo_pregnant.df_resid - res.df_resid\n",
    "print(\"Degré de liberté du test : %.d\" % (ddl))\n",
    "#p-value\n",
    "pvalue = 1.0 - scipy.stats.chi2.cdf(LR_pregnant,ddl)\n",
    "print(\"Probabilité critique : %.4f\" % (pvalue))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Très proche du résultat obtenu avec Wald finalement (en termes de p-value tout du moins). Ce n’est\n",
    "pas très étonnant. Notre effectif est assez grand. L’approximation normale est d’autant meilleure que\n",
    "le ratio entre le nombre d’observations et le nombre de variables augmente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tester un groupe de coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# a) Le plus simple, passer par la vraisemblance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L’approche est aisément généralisable au test de significativité de plusieurs coefficients. \n",
    "\n",
    "Par exemple, vérifions que les coefficients de (Sex, Education et Occupation) peuvent être considérés\n",
    "comme simultanément nuls (H0 : a_pregnant = a_pedigree = a_age = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 568 entries, 0 to 567\n",
      "Data columns (total 8 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   const      568 non-null    float64\n",
      " 1   plasma     568 non-null    int64  \n",
      " 2   diastolic  568 non-null    int64  \n",
      " 3   triceps    568 non-null    int64  \n",
      " 4   serum      568 non-null    int64  \n",
      " 5   bodymass   568 non-null    float64\n",
      " 6   alea1      568 non-null    float64\n",
      " 7   alea2      568 non-null    float64\n",
      "dtypes: float64(4), int64(4)\n",
      "memory usage: 35.6 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#définir la matrice des X sans les 3 variables\n",
    "XTrain_wo_3 = XTrainBis.drop(columns=['pregnant','pedigree','age'])\n",
    "print(XTrain_wo_3.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nous réalisons la régression sans les 3 variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.500100\n",
      "         Iterations 6\n"
     ]
    }
   ],
   "source": [
    "#régression sans les 3 variables\n",
    "lr_wo_3 = Logit(yTrain,XTrain_wo_3)\n",
    "#résultats\n",
    "res_wo_3 = lr_wo_3.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons par la suite réaliser le test en calculant la statistique du rapport de vraisemblance (par\n",
    "l’écart entre les déviances) et calculer la p-value avec les degrés de liberté idoines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistique de test : 27.1966\n",
      "Degré de liberté du test : 3\n",
      "Probabilité critique : 0.0000\n"
     ]
    }
   ],
   "source": [
    "#statistique de test - différence entre les déviances\n",
    "LR_3 = (-2) * res_wo_3.llf - (-2) * res.llf\n",
    "print(\"Statistique de test : %.4f\" % (LR_3))\n",
    "#degré de liberté = 3 puisque 3 coef. retirés\n",
    "ddl = res_wo_3.df_resid - res.df_resid\n",
    "print(\"Degré de liberté du test : %.d\" % (ddl))\n",
    "#p-value\n",
    "pvalue = 1.0 - scipy.stats.chi2.cdf(LR_3,ddl)\n",
    "print(\"Probabilité critique : %.4f\" % (pvalue))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion : \n",
    "La nullité simultanée des coefficients de (pregnant, pedigree, age) n’est pas\n",
    "démentie par les données au risque 5%.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# b) Test de Wald – Calcul matriciel"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Au prix d’une gymnastique matricielle un peu complexe, il est également possible de s’appuyer sur la\n",
    "normalité asymptotique des estimateurs du maximum de vraisemblance, et d’appliquer le principe du\n",
    "test de Wald, pour tester la nullité simultanée de plusieurs coefficients. Le\n",
    "secret réside dans l’utilisation à bon escient des covariances estimées des coefficients estimés puis\n",
    "les variables, et donc les coefficients, ne sont pas indépendantes.\n",
    "Nous testons de nouveau la nullité des coefficients de (pregnant, pedigree, age)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              const  pregnant    plasma     diastolic   triceps         serum  \\\n",
      "const      0.786618  0.000090 -0.001666 -1.036677e-03 -0.000101  1.319138e-04   \n",
      "pregnant   0.000090  0.001475  0.000012 -7.363145e-06 -0.000014  1.762133e-06   \n",
      "plasma    -0.001666  0.000012  0.000017 -2.689255e-06  0.000004 -1.417663e-06   \n",
      "diastolic -0.001037 -0.000007 -0.000003  3.991344e-05 -0.000008  4.019536e-07   \n",
      "triceps   -0.000101 -0.000014  0.000004 -7.722340e-06  0.000062 -3.123143e-06   \n",
      "serum      0.000132  0.000002 -0.000001  4.019536e-07 -0.000003  9.758778e-07   \n",
      "bodymass  -0.009174  0.000029 -0.000002 -1.938876e-05 -0.000040 -3.804739e-07   \n",
      "pedigree  -0.068775  0.001217  0.000056 -9.905162e-05 -0.000287 -2.812299e-05   \n",
      "age       -0.002464 -0.000234 -0.000007 -1.554074e-05  0.000013  1.115616e-07   \n",
      "alea1     -0.074063 -0.000659 -0.000004 -8.982406e-05  0.000176 -1.295055e-05   \n",
      "alea2     -0.082810 -0.000128 -0.000012  1.701037e-05 -0.000051  3.317227e-05   \n",
      "\n",
      "               bodymass  pedigree           age     alea1     alea2  \n",
      "const     -9.173501e-03 -0.068775 -2.463559e-03 -0.074063 -0.082810  \n",
      "pregnant   2.876265e-05  0.001217 -2.338130e-04 -0.000659 -0.000128  \n",
      "plasma    -1.745310e-06  0.000056 -7.238244e-06 -0.000004 -0.000012  \n",
      "diastolic -1.938876e-05 -0.000099 -1.554074e-05 -0.000090  0.000017  \n",
      "triceps   -3.959014e-05 -0.000287  1.289499e-05  0.000176 -0.000051  \n",
      "serum     -3.804739e-07 -0.000028  1.115616e-07 -0.000013  0.000033  \n",
      "bodymass   3.133581e-04  0.000424  2.233191e-05  0.000116  0.000157  \n",
      "pedigree   4.236407e-04  0.126805 -1.276692e-04  0.005743  0.001076  \n",
      "age        2.233191e-05 -0.000128  1.271139e-04  0.000091 -0.000043  \n",
      "alea1      1.157683e-04  0.005743  9.067283e-05  0.138928  0.007149  \n",
      "alea2      1.569807e-04  0.001076 -4.291534e-05  0.007149  0.143015  \n"
     ]
    }
   ],
   "source": [
    "#afficher la matrice de var-covar des coefs. estimés.\n",
    "print(res.cov_params())\n",
    "#récupération sous une forme matricielle\n",
    "vcov = res.cov_params().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8869147  0.03840145 0.00411233 0.00631771 0.00789955 0.00098787\n",
      " 0.01770192 0.35609645 0.01127448 0.37273084 0.37817354]\n"
     ]
    }
   ],
   "source": [
    "#nous avons bien le carré des ecarts-type estimés sur la diagonale\n",
    "#à confronter avec les sorties de summary (page 6)\n",
    "print(numpy.sqrt(numpy.diagonal(vcov)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reproduisons les étapes de notre support pour (H0 : a_pregnant = a_pedigree = a_age = 0)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Récupération de la sous-partie de la matrice de variance covariance qui nous concerne."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.47467137e-03 2.87626523e-05 1.21725235e-03]\n",
      " [2.87626523e-05 3.13358088e-04 4.23640655e-04]\n",
      " [1.21725235e-03 4.23640655e-04 1.26804685e-01]]\n"
     ]
    }
   ],
   "source": [
    "#indice des coefficients concernés\n",
    "indices = [1,6,7]\n",
    "#sous-matrice de var.covar\n",
    "subset_vcov = numpy.zeros(shape=(3,3))\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "         subset_vcov[i,j] = vcov[indices[i],indices[j]]\n",
    "#vérification\n",
    "print(subset_vcov)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous inversions ensuite cette sous-matrice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 684.44802613  -54.18651505   -6.38927779]\n",
      " [ -54.18651505 3210.00628009  -10.20412224]\n",
      " [  -6.38927779  -10.20412224    7.98156825]]\n"
     ]
    }
   ],
   "source": [
    "#inversion de cette matrice\n",
    "inv_subset_vcov = numpy.linalg.inv(subset_vcov)\n",
    "print(inv_subset_vcov)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous récupérons le sous-vecteur des coefficients estimés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#coefficients estimés\n",
    "a = res.params[indices].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reste à calculer la forme quadratique correspondant à la statistique de test et\n",
    "la probabilité critique associée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stat. de test : 36.4719\n",
      "p-value : 0.0000\n"
     ]
    }
   ],
   "source": [
    "#produit matriciel\n",
    "stat_3 = numpy.dot(a,numpy.dot(inv_subset_vcov,a))\n",
    "print(\"Stat. de test : %.4f\" % (stat_3))\n",
    "#p-value (ddl = 3 puisque 3 coef. à tester)\n",
    "pvalue = 1.0 - scipy.stats.chi2.cdf(stat_3,3)\n",
    "print(\"p-value : %.4f\" % (pvalue))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encore une fois, du fait de l’effectif assez élevé, les résultats sont très similaires à ceux du test du\n",
    "rapport de vraisemblance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# c) Test de Wald avec l’outil dédié"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En réalité, on s’est un peu embêté pour rien dans la section précédente. « Statsmodels » propose\n",
    "l’outil wald_test() pour réaliser les tests généralisés.\n",
    "\n",
    "L’enjeu réside alors dans la définition de la matrice M permettant de spécifier les coefficients \n",
    "à tester (H0 : a_pregnant en position 1, a_pedigree en position 7 et a_age en position 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Wald test (chi2): statistic=[[85.32440874]], p-value=2.2106504681197234e-18, df_denom=3>\n"
     ]
    }
   ],
   "source": [
    "#matrice des coefficients à tester\n",
    "M = [[1,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,1,0,0,0,0],[0,0,0,0,0,0,0,1,0,0,0]]\n",
    "#calculer la stat. de test\n",
    "stat_3bis = res.wald_test(M)\n",
    "print(stat_3bis)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performances prédictives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apprécier le modèle sur un second jeu de données à part, communément appelé « échantillon test »,\n",
    "permet d’obtenir une estimation (plus) représentative de ses performances dans la population. \n",
    "\n",
    "On parle de schéma d’évaluation « holdout »"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous utilisons les données issues de la seconde feuille « test » de notre classeur Excel\n",
    "« infidelites_python.xlsx » dans cette section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# a) Prédiction et matrice de confusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme pour en apprentissage, il faut tout d’abord ajouter la colonne de constante\n",
    "dans la matrice des variables explicatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 200 entries, 0 to 199\n",
      "Data columns (total 11 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   const      200 non-null    float64\n",
      " 1   pregnant   200 non-null    int64  \n",
      " 2   plasma     200 non-null    int64  \n",
      " 3   diastolic  200 non-null    int64  \n",
      " 4   triceps    200 non-null    int64  \n",
      " 5   serum      200 non-null    int64  \n",
      " 6   bodymass   200 non-null    float64\n",
      " 7   pedigree   200 non-null    float64\n",
      " 8   age        200 non-null    int64  \n",
      " 9   alea1      200 non-null    float64\n",
      " 10  alea2      200 non-null    float64\n",
      "dtypes: float64(5), int64(6)\n",
      "memory usage: 17.3 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#préparation de l'échantillon test\n",
    "#par adjonction de la constante\n",
    "XTest_Bis = add_constant(XTest)\n",
    "print(XTest_Bis.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous réalisons la prédiction en faisant appel à la fonction predict()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    200.000000\n",
      "mean       0.372058\n",
      "std        0.268406\n",
      "min        0.002747\n",
      "25%        0.142682\n",
      "50%        0.312087\n",
      "75%        0.579246\n",
      "max        0.991720\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#calcul de la prédiction sur l'échantillon test\n",
    "predProbaSm = res.predict(XTest_Bis)\n",
    "#à l'évidence nous avons les probabilités d'affectation\n",
    "print(predProbaSm.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous comprenons à travers les statistiques descriptives, parce que ce comportement peut\n",
    "varier d’un outil à l’autre (cf. par exemple pour « Scikit-Learn » plus bas), que nous obtenons les\n",
    "probabilités d’affectation à la classe cible.\n",
    "Nous les convertissons en classes prédites {0, 1} en les comparant avec la valeur seuil 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1]), array([139,  61], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "#convertir en prédiction brute\n",
    "predSm = numpy.where(predProbaSm > 0.5, 1, 0)\n",
    "print(numpy.unique(predSm,return_counts=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sur les 200 individus en test, 184 sont associés à la classe « 0 », 16 à « 1 ». Nous formons la\n",
    "matrice de confusion en opposant les classes observées et prédites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col_0      0   1\n",
      "diabete         \n",
      "0        115  13\n",
      "1         24  48\n"
     ]
    }
   ],
   "source": [
    "#matrice de confusion\n",
    "mcSm = pandas.crosstab(yTest,predSm)\n",
    "print(mcSm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transformer en matrice Numpy\n",
    "mcSmNumpy = mcSm.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Et nous pouvons en déduire les différents indicateurs de performances, notamment le taux de\n",
    "reconnaissance (ou taux de succès) et le taux d’erreur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taux de reconnaissance : 0.8150\n",
      "Taux d'erreur' : 0.1850\n"
     ]
    }
   ],
   "source": [
    "#taux de reconnaissance\n",
    "accSm = numpy.sum(numpy.diagonal(mcSmNumpy))/numpy.sum(mcSmNumpy)\n",
    "print(\"Taux de reconnaissance : %.4f\" % (accSm))\n",
    "#taux d'erreur\n",
    "errSm = 1.0 - accSm\n",
    "print(\"Taux d'erreur' : %.4f\" % (errSm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# b) Courbe ROC en test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour construire la courbe ROC (receiver operating characteristics) sur l’échantillon test, nous avons\n",
    "besoin des valeurs observées de la classe et des probabilités d’affectation fournies par le modèle.\n",
    "\n",
    "Nous préférons aller à l’essentiel dans ce document. Notre objectif est d’explorer les outils statistiques à\n",
    "notre disposition sous Python. \n",
    "\n",
    "Nous utilisons la fonction roc_curve() du package « scikit-learn », que nous étudierons de manière approfondie \n",
    "plus loin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#importer le module metrics\n",
    "#de la librairie scikit-learn\n",
    "import sklearn.metrics as metrics\n",
    "#colonnes pour les courbes ROC\n",
    "#fpr (false positive rate -- taux de faux positifs) en abscisse\n",
    "#tpr (true positive rate – taux de vrais positifs) en ordonnée\n",
    "#pos_label = 1 pour indiquer la modalité cible\n",
    "fprSm, tprSm, _ = metrics.roc_curve(yTest,predProbaSm,pos_label=1)\n",
    "#graphique -- construire la diagonale de référence\n",
    "#cas du modèle qui ne fait pas mieux que l’affectation des probabilités\n",
    "#au hasard – notre courbe ne doit pas passer en dessous\n",
    "#plus il s’en écarte vers le haut, mieux c’est\n",
    "plt.plot(numpy.arange(0,1.1,0.1),numpy.arange(0,1.1,0.1),'b')\n",
    "#rajouter notre diagramme\n",
    "plt.plot(fprSm,tprSm,\"g\")\n",
    "#titre\n",
    "plt.title(\"Courbe ROC\")\n",
    "#faire apparaître le graphique\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour calculer l’AUC (aire sous la courbe), nous faisons appel à la fonction roc_auc_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC : 0.8529\n"
     ]
    }
   ],
   "source": [
    "#valeur de l'AUC\n",
    "aucSm = metrics.roc_auc_score(yTest,predProbaSm)\n",
    "print(\"AUC : %.4f\" % (aucSm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II- Régression logistique avec “scikit-learn”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La libraire « scikit-learn » est très populaire auprès des data scientists. \n",
    "\n",
    "Elle est très complète ; son mode opératoire est particulièrement cohérent, \n",
    "quelle que soit la famille de méthode de machine learning que nous\n",
    "utilisons ; il est très facile d’enchaîner des opérations complexes, notamment avec le mécanisme des\n",
    "« pipeline ». \n",
    "\n",
    "Voyons comment se comporte l’algorithme de régression logistique qu’elle propose."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Importation et vérification de version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sage précaution toujours, nous affichons le numéro de version de la librairie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23.2\n"
     ]
    }
   ],
   "source": [
    "#importation\n",
    "import sklearn\n",
    "#version\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Régression logistique avec scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous instancions une régression logistique sans pénalité c.-à-d. ni Ridge, ni Lasso. Nous lançons\n",
    "l’estimation des paramètres avec la fonction fit() qui prend en entrée les données en apprentissage\n",
    "avec la matrice des explicatives (il n’est pas nécessaire d’adjoindre la constante) et le vecteur des\n",
    "classes observées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MSI\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(penalty='none')"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#importation de la classe de calcul\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "#instanciation\n",
    "lrSk = LogisticRegression(penalty='none')\n",
    "#lancement des calculs\n",
    "#pas nécessaire de rajouter la constante\n",
    "lrSk.fit(XTrain,yTrain)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Un message sur fond rouge (sous Jupyter Notebook) n’est jamais engageant. L’outil nous annonce\n",
    "que le processus n’a pas convergé alors que, dixit la documentation, le nombre maximal d’itération\n",
    "par défaut est (max_iter = 100). Rappelons que sous « statsmodels », 6 itérations ont été suffisantes\n",
    "(page 5). Pour solutionner le problème, « Scikit-learn » nous propose de : soit augmenter le nombre\n",
    "d’itérations (un peu bourrin quand-même comme solution), soit de standardiser les données avant de\n",
    "lancer l’algorithme (ah bon ? quel rapport avec la régression ? pourquoi nous n’avons pas eu à le\n",
    "faire sous « statsmodels » ?).\n",
    "Nous reviendrons sur cet écueil dans la section suivante. Pour l’instant, affichons les coefficients\n",
    "estimés, ceux des variables…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         var      coef\n",
      "0   pregnant  0.122988\n",
      "1     plasma  0.024998\n",
      "2  diastolic -0.025163\n",
      "3    triceps -0.001375\n",
      "4      serum -0.000404\n",
      "5   bodymass  0.067111\n",
      "6   pedigree  0.265359\n",
      "7        age  0.008114\n",
      "8      alea1 -2.077822\n",
      "9      alea2 -0.829188\n"
     ]
    }
   ],
   "source": [
    "#affichage des coefficients\n",
    "print(pandas.DataFrame({\"var\":XTrain.columns,\"coef\":lrSk.coef_[0]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-3.49965505]\n"
     ]
    }
   ],
   "source": [
    "# Affichage de la constante :\n",
    "print(lrSk.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Force est de constater qu’il y a eu un problème durant le processus d’apprentissage. \n",
    "\n",
    "Les coefficients estimés diffèrent sensiblement de ceux obtenus sous « statsmodels »"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Régression logistique sur données standardisées"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La documentation de la régression logistique sous « scikit-learn » nous indique les différents\n",
    "algorithmes d’optimisation qu’il est susceptible d’utiliser (option « solver »), qui sont pour la plupart\n",
    "des succédanés de la descente du gradient. Ces approches, certains plus que d’autres, sont\n",
    "sensibles aux différences d’échelles entre les variables, d’où l’indication « scale the data » dans le\n",
    "« warning » envoyé par la méthode fit().\n",
    "\n",
    "\n",
    "Dans ce qui suit, nous centrons et réduisons les données d’apprentissage avant de relancer la\n",
    "modélisation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DescribeResult(nobs=568, minmax=(array([-1.13103942, -3.72232402, -3.70291218, -1.31284418, -0.68471052,\n",
      "       -4.15422422, -1.20987055, -1.03544449, -1.70981217, -1.78420532]), array([3.35938737, 2.40521662, 2.81830878, 4.90442497, 6.38329182,\n",
      "       3.01297804, 5.89787709, 4.04415074, 1.76473061, 1.73794374])), mean=array([-1.25095552e-17,  1.31350330e-16,  3.71377420e-16,  1.25095552e-17,\n",
      "       -2.50191104e-17, -3.07265950e-16, -3.06484103e-16, -1.89207023e-16,\n",
      "        1.12585997e-16, -2.00152883e-16]), variance=array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), skewness=array([ 0.90403569,  0.17163385, -1.8352426 ,  0.12232248,  2.36846201,\n",
      "       -0.46474656,  1.9126523 ,  1.18020159,  0.04466256, -0.03653212]), kurtosis=array([ 0.10382287,  0.62481149,  5.44373725, -0.30612943,  7.58959687,\n",
      "        2.58492601,  5.67541803,  0.79644501, -1.18644688, -1.14488371]))\n"
     ]
    }
   ],
   "source": [
    "#importation de l'outil\n",
    "from sklearn import preprocessing\n",
    "#instanciation\n",
    "stds = preprocessing.StandardScaler()\n",
    "#transformation\n",
    "ZTrain = stds.fit_transform(XTrain)\n",
    "print(scipy.stats.describe(ZTrain,axis=0,ddof=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les variables sont bien de moyenne nulle et d’écart-type unitaire.\n",
    "Nous instancions une nouvelle version de la régression et nous affichons les coefficients estimés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         var      coef\n",
      "0   pregnant  0.316500\n",
      "1     plasma  1.039883\n",
      "2  diastolic -0.307838\n",
      "3    triceps  0.047522\n",
      "4      serum -0.111341\n",
      "5   bodymass  0.726688\n",
      "6   pedigree  0.250720\n",
      "7        age  0.269074\n",
      "8      alea1 -0.063863\n",
      "9      alea2  0.108008\n"
     ]
    }
   ],
   "source": [
    "#instanciation\n",
    "lrSkStd = LogisticRegression(penalty='none')\n",
    "#lancement des calculs -- pas nécessaire de rajouter la constante\n",
    "lrSkStd.fit(ZTrain,yTrain)\n",
    "#affichage des coefficients\n",
    "print(pandas.DataFrame({\"var\":XTrain.columns,\"coef\":lrSkStd.coef_[0]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pas de message d’erreur ou de warning intempestifs cette fois-ci. Mais les coefficients obtenus sont\n",
    "très différents de ceux de « statsmodels » (page 6) puisque nous travaillons sur des données\n",
    "transformées. \n",
    "\n",
    "Nous devons les « dé-standardiser » en les divisant par les écarts-type des variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         var      coef\n",
      "0   pregnant  0.094748\n",
      "1     plasma  0.032181\n",
      "2  diastolic -0.016455\n",
      "3    triceps  0.002984\n",
      "4      serum -0.000930\n",
      "5   bodymass  0.094697\n",
      "6   pedigree  0.791673\n",
      "7        age  0.022780\n",
      "8      alea1 -0.224136\n",
      "9      alea2  0.381564\n"
     ]
    }
   ],
   "source": [
    "#correction des coefficients - dé-standardisation\n",
    "#par les écarts-type utilisés lors de la standardisation des variables\n",
    "coefUnstd = lrSkStd.coef_[0] / stds.scale_\n",
    "#affichage des coefficients corrigés\n",
    "print(pandas.DataFrame({\"var\":XTrain.columns,\"coef\":coefUnstd}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant seulement les paramètres estimés sont tout à fait cohérents. \n",
    "\n",
    "Note : Il y a quandmême de petites différences mais elles sont négligeables dans la mesure où une solution exacte\n",
    "n’est pas possible de toute manière. \n",
    "\n",
    "Les heuristiques de calcul engendre une précision approximative que l’on peut piloter avec l’option « tol » \n",
    "(pour tolérance d’erreur).\n",
    "\n",
    "Nous devons procéder de même avec la constante estimée de la régression mais, en sus des écartstype, les moyennes des \n",
    "variables entrent également dans le calcul."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-8.19018088]\n"
     ]
    }
   ],
   "source": [
    "#pour la constante, l'opération est plus complexe\n",
    "interceptUnStd = lrSkStd.intercept_ + numpy.sum(lrSkStd.coef_[0]*(-stds.mean_/stds.scale_))\n",
    "print(interceptUnStd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Calcul de la log-vraisemblance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les sorties de « scikit-learn » sont peu dissertes. Nous n’avons pas d’indications sur la valeur de\n",
    "la log-vraisemblance à l’issue du processus d’optimisation. \n",
    "\n",
    "Dans cette section, nous la calculons explicitement à partir des classes observées et des probabilité d’appartenance \n",
    "aux classes fournies par la méthode predict_proba()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.27042793 0.72957207]\n",
      " [0.35296087 0.64703913]\n",
      " [0.43394476 0.56605524]\n",
      " [0.76161945 0.23838055]\n",
      " [0.90705449 0.09294551]]\n"
     ]
    }
   ],
   "source": [
    "#probabilités d'affectation\n",
    "proba01 = lrSkStd.predict_proba(ZTrain)\n",
    "#affichage des 5 premières valeurs\n",
    "print(proba01[:5,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les probabilités sont sur deux colonnes. La première, n°0, pour l’appartenance à (Y = 0), la\n",
    "seconde pour (Y = 1). \n",
    "\n",
    "Nous récupérons cette dernière.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DescribeResult(nobs=568, minmax=(0.003367180639822714, 0.9757792363973964), mean=0.34507103917506676, variance=0.07056943685679869, skewness=0.7060045771178762, kurtosis=-0.7122546378569581)\n"
     ]
    }
   ],
   "source": [
    "#récupération de la colonne n°1\n",
    "proba1 = proba01[:,1]\n",
    "#description stat\n",
    "print(scipy.stats.describe(proba1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons calculer la log-vraisemblance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-270.45852163242375\n"
     ]
    }
   ],
   "source": [
    "#log-vraisemblance\n",
    "log_likelihood = numpy.sum(yTrain*numpy.log(proba1)+(1.0-yTrain)*numpy.log(1.0-proba1))\n",
    "print(log_likelihood)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encore une fois, nous sommes cohérents avec « statsmodels »"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Performances prédictives en test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour appliquer le modèle sur l’échantillon test, il faut au préalable administrer la même\n",
    "transformation (centrage, réduction) sur ce second dataset en utilisant les paramètres (moyennes,\n",
    "écarts-type) calculés sur l’échantillon d’apprentissage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DescribeResult(nobs=200, minmax=(array([-1.13103942, -3.72232402, -3.70291218, -1.31284418, -0.68471052,\n",
      "       -4.15422422, -1.14040344, -1.03544449, -1.73788928, -1.77007433]), array([3.95811094, 2.43616379, 2.17687721, 2.64359983, 3.85184417,\n",
      "       4.58976253, 6.18521829, 3.28221146, 1.77174988, 1.69555078])), mean=array([ 0.07688538,  0.07303751, -0.03472539, -0.08885857, -0.06918443,\n",
      "        0.05689804,  0.12991304,  0.00333274,  0.03026693, -0.13146248]), variance=array([1.05782456, 0.91065571, 1.26423059, 1.00305875, 0.71158337,\n",
      "       1.2056961 , 1.34507102, 0.9614728 , 1.14899534, 0.9999305 ]), skewness=array([ 0.88464151,  0.19645013, -1.81317668,  0.07374474,  1.64418516,\n",
      "       -0.36683607,  1.84434571,  0.96811782, -0.01251388,  0.10600105]), kurtosis=array([ 0.25025891,  0.62399596,  4.29171573, -1.15963716,  3.053313  ,\n",
      "        4.46054942,  4.81083593,  0.1219992 , -1.33920178, -1.17954876]))\n"
     ]
    }
   ],
   "source": [
    "#transformation de l'échantillon test\n",
    "ZTest = stds.transform(XTest)\n",
    "#stat. descriptives\n",
    "print(scipy.stats.describe(ZTest,axis=0,ddof=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les moyennes et écarts-type calculés ne sont pas forcément nuls et unitaires sur ce second\n",
    "dataset transformé puisque les moyennes et écarts-type utilisées proviennent d’un autre\n",
    "échantillon (d’apprentissage).\n",
    "\n",
    "Nous appliquons le modèle (predict) et nous calculons la matrice de confusion avec la fonction\n",
    "confusion_matrix() du module « metrics » de « scikit-learn »."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1], dtype=int64), array([139,  61], dtype=int64))\n",
      "[[115  13]\n",
      " [ 24  48]]\n"
     ]
    }
   ],
   "source": [
    "#appliquer la prédiction\n",
    "predSk = lrSkStd.predict(ZTest)\n",
    "print(numpy.unique(predSk,return_counts=True))\n",
    "#matrice de confusion\n",
    "print(metrics.confusion_matrix(yTest,predSk))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons calculer individuellement les différents indicateurs mais, avec la fonction\n",
    "classification_report(), nous disposons directement d’ un rapport détaillé."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.90      0.86       128\n",
      "           1       0.79      0.67      0.72        72\n",
      "\n",
      "    accuracy                           0.81       200\n",
      "   macro avg       0.81      0.78      0.79       200\n",
      "weighted avg       0.81      0.81      0.81       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#rapport sur la qualité de prédiction\n",
    "print(metrics.classification_report(yTest,predSk))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La matrice de confusion et, par conséquent, le taux de reconnaissance en test de 81%, sont\n",
    "identiques à ceux de « statsmodels »"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coclusion : \n",
    " Les deux librairies étudiées, « statsmodels » et « scikitlearn », sont différentes dans leur philosophie et les fonctionnalités proposées. La première,\n",
    "comme son nom l’indique, est empreinte d’une forte culture statistique. \n",
    "\n",
    "La seconde a une approche plutôt « machine learning ». Mais elles se rejoignent dans les résultats. C’est ce qui\n",
    "importe en définitive.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
